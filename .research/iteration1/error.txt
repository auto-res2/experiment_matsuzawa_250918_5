Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/toma/pt-80-1-a-13/_work/experiment_matsuzawa_250918_5/experiment_matsuzawa_250918_5/src/main.py", line 11, in <module>
    from . import preprocess
  File "/home/toma/pt-80-1-a-13/_work/experiment_matsuzawa_250918_5/experiment_matsuzawa_250918_5/src/preprocess.py", line 140
    final_labeled_data.append((f"<LID:unk}> {text}", reward, safety_label))
                                                   ^
SyntaxError: f-string: single '}' is not allowed
2025-09-18 15:34:33,236 - INFO - Loading configuration from config/smoke_test.yaml
2025-09-18 15:34:33,278 - INFO - Environment set up with random seed: 42
2025-09-18 15:34:33,278 - INFO - ====== Starting Phase 1: Data Preprocessing ======
2025-09-18 15:34:33,278 - INFO - Starting preprocessing...
2025-09-18 15:34:33,280 - INFO - fastText language identification model not found. Downloading...
2025-09-18 15:34:35,160 - INFO - fastText model downloaded successfully.
Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.
2025-09-18 15:34:35,471 - INFO - Loading Alpaca dataset (as PromptSource substitute)
Generating train split:   0%|          | 0/52002 [00:00<?, ? examples/s]Generating train split:  62%|██████▏   | 32000/52002 [00:00<00:00, 314372.88 examples/s]Generating train split: 100%|██████████| 52002/52002 [00:00<00:00, 218434.61 examples/s]
2025-09-18 15:34:41,855 - INFO - Loading LAION-Aesthetics dataset (as Stable Diffusion logs substitute)
Generating train split:   0%|          | 0/591753 [00:00<?, ? examples/s]Generating train split: 100%|██████████| 591753/591753 [00:00<00:00, 2428646.75 examples/s]Generating train split: 100%|██████████| 591753/591753 [00:00<00:00, 1521722.61 examples/s]
2025-09-18 15:34:48,625 - INFO - Loading DETOX dataset for safety labels
Downloading data:   0%|          | 0/27 [00:00<?, ?files/s]Downloading data:   4%|▎         | 1/27 [00:09<03:59,  9.22s/files]Downloading data:   7%|▋         | 2/27 [00:18<03:58,  9.52s/files]Downloading data:  11%|█         | 3/27 [00:27<03:40,  9.17s/files]Downloading data:  15%|█▍        | 4/27 [00:36<03:29,  9.12s/files]Downloading data:  19%|█▊        | 5/27 [00:46<03:24,  9.29s/files]Downloading data:  22%|██▏       | 6/27 [00:55<03:11,  9.14s/files]Downloading data:  26%|██▌       | 7/27 [01:04<03:01,  9.09s/files]Downloading data:  30%|██▉       | 8/27 [01:13<02:51,  9.04s/files]2025-09-18 15:36:26,315 - INFO - Loading configuration from config/smoke_test.yaml
2025-09-18 15:36:26,354 - INFO - Environment set up with random seed: 42
2025-09-18 15:36:26,354 - INFO - ====== Starting Phase 1: Data Preprocessing ======
2025-09-18 15:36:26,354 - INFO - Starting preprocessing...
Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.
2025-09-18 15:36:26,536 - INFO - Loading Alpaca dataset (as PromptSource substitute)
2025-09-18 15:36:29,481 - INFO - Loading LAION-Aesthetics dataset (as Stable Diffusion logs substitute)
2025-09-18 15:36:32,167 - INFO - Loading DETOX dataset for safety labels
Downloading data:   0%|          | 0/27 [00:00<?, ?files/s]Downloading data:   4%|▎         | 1/27 [00:00<00:04,  5.44files/s]Downloading data:  33%|███▎      | 9/27 [00:06<00:13,  1.37files/s]Downloading data:  37%|███▋      | 10/27 [00:15<00:32,  1.94s/files]Downloading data:  41%|████      | 11/27 [00:24<00:49,  3.09s/files]Downloading data:  44%|████▍     | 12/27 [00:32<01:01,  4.10s/files]Downloading data:  48%|████▊     | 13/27 [00:43<01:16,  5.50s/files]Downloading data:  52%|█████▏    | 14/27 [00:52<01:21,  6.24s/files]Downloading data:  56%|█████▌    | 15/27 [01:01<01:23,  6.97s/files]Downloading data:  59%|█████▉    | 16/27 [01:10<01:22,  7.50s/files]Downloading data:  63%|██████▎   | 17/27 [01:18<01:17,  7.74s/files]Downloading data:  67%|██████▋   | 18/27 [01:28<01:16,  8.47s/files]Downloading data:  70%|███████   | 19/27 [01:37<01:07,  8.50s/files]Downloading data:  74%|███████▍  | 20/27 [01:46<01:01,  8.79s/files]Downloading data:  78%|███████▊  | 21/27 [02:01<01:02, 10.45s/files]Downloading data:  81%|████████▏ | 22/27 [02:10<00:50, 10.03s/files]Downloading data:  85%|████████▌ | 23/27 [02:18<00:38,  9.59s/files]Downloading data:  89%|████████▉ | 24/27 [02:28<00:28,  9.45s/files]Downloading data:  93%|█████████▎| 25/27 [02:37<00:18,  9.34s/files]Downloading data:  96%|█████████▋| 26/27 [02:47<00:09,  9.64s/files]Downloading data: 100%|██████████| 27/27 [05:14<00:00, 50.67s/files]Downloading data: 100%|██████████| 27/27 [05:14<00:00, 11.64s/files]
Generating train split:   0%|          | 0/1949977 [00:00<?, ? examples/s]Generating train split:   1%|          | 10000/1949977 [00:00<02:02, 15804.80 examples/s]Generating train split:   1%|          | 20000/1949977 [00:00<01:23, 23240.87 examples/s]Generating train split:   2%|▏         | 30000/1949977 [00:01<01:12, 26402.16 examples/s]Generating train split:   2%|▏         | 40000/1949977 [00:01<01:07, 28399.85 examples/s]Generating train split:   3%|▎         | 50000/1949977 [00:01<01:02, 30295.24 examples/s]Generating train split:   3%|▎         | 60000/1949977 [00:02<01:01, 30756.45 examples/s]Generating train split:   4%|▍         | 82222/1949977 [00:02<00:59, 31545.24 examples/s]Generating train split:   5%|▍         | 92222/1949977 [00:03<01:27, 21213.87 examples/s]Generating train split:   6%|▋         | 122222/1949977 [00:03<00:47, 38685.68 examples/s]Generating train split:   7%|▋         | 132222/1949977 [00:04<00:47, 37959.94 examples/s]Generating train split:   8%|▊         | 154444/1949977 [00:04<00:50, 35850.46 examples/s]Generating train split:   8%|▊         | 164444/1949977 [00:05<00:49, 35979.40 examples/s]Generating train split:   9%|▉         | 174444/1949977 [00:06<01:28, 19968.64 examples/s]Generating train split:  11%|█         | 214444/1949977 [00:06<00:42, 40720.37 examples/s]Generating train split:  12%|█▏        | 226666/1949977 [00:07<00:50, 34330.04 examples/s]Generating train split:  12%|█▏        | 236666/1949977 [00:07<00:48, 35494.61 examples/s]Generating train split:  13%|█▎        | 246666/1949977 [00:07<00:46, 36804.11 examples/s]Generating train split:  13%|█▎        | 256666/1949977 [00:08<01:11, 23594.65 examples/s]Generating train split:  15%|█▍        | 288888/1949977 [00:08<00:37, 44343.82 examples/s]Generating train split:  16%|█▌        | 308888/1949977 [00:09<00:49, 33356.61 examples/s]Generating train split:  16%|█▋        | 318888/1949977 [00:09<00:48, 33895.78 examples/s]Generating train split:  17%|█▋        | 328888/1949977 [00:10<00:46, 34775.84 examples/s]Generating train split:  17%|█▋        | 338888/1949977 [00:11<01:16, 21020.60 examples/s]Generating train split:  19%|█▉        | 371110/1949977 [00:12<00:53, 29554.16 examples/s]Generating train split:  20%|█▉        | 381110/1949977 [00:12<00:49, 31616.33 examples/s]Generating train split:  20%|██        | 391110/1949977 [00:12<00:48, 32331.67 examples/s]Generating train split:  21%|██        | 401110/1949977 [00:12<00:45, 33823.70 examples/s]Generating train split:  21%|██        | 411110/1949977 [00:13<00:44, 34754.77 examples/s]Generating train split:  22%|██▏       | 421110/1949977 [00:14<01:28, 17272.45 examples/s]Generating train split:  23%|██▎       | 443332/1949977 [00:15<01:05, 22905.37 examples/s]Generating train split:  23%|██▎       | 453332/1949977 [00:15<00:58, 25716.70 examples/s]Generating train split:  24%|██▍       | 463332/1949977 [00:15<00:52, 28203.25 examples/s]Generating train split:  24%|██▍       | 473332/1949977 [00:15<00:49, 29900.41 examples/s]Generating train split:  25%|██▍       | 483332/1949977 [00:16<00:46, 31354.27 examples/s]Generating train split:  25%|██▌       | 493332/1949977 [00:16<00:43, 33235.77 examples/s]Generating train split:  26%|██▌       | 503332/1949977 [00:17<01:10, 20501.41 examples/s]Generating train split:  26%|██▋       | 515554/1949977 [00:17<01:05, 21969.93 examples/s]Generating train split:  27%|██▋       | 525554/1949977 [00:17<00:57, 24803.63 examples/s]Generating train split:  27%|██▋       | 535554/1949977 [00:18<00:51, 27272.96 examples/s]Generating train split:  28%|██▊       | 545554/1949977 [00:18<00:44, 31258.39 examples/s]Generating train split:  28%|██▊       | 555554/1949977 [00:18<00:43, 32383.92 examples/s]Generating train split:  29%|██▉       | 565554/1949977 [00:19<00:41, 33555.16 examples/s]Generating train split:  30%|██▉       | 577776/1949977 [00:19<00:56, 24427.18 examples/s]Generating train split:  30%|███       | 587776/1949977 [00:20<01:02, 21783.34 examples/s]Generating train split:  31%|███       | 597776/1949977 [00:20<00:57, 23579.55 examples/s]Generating train split:  31%|███       | 607776/1949977 [00:21<00:52, 25566.07 examples/s]Generating train split:  32%|███▏      | 617776/1949977 [00:21<00:46, 28837.25 examples/s]Generating train split:  32%|███▏      | 627776/1949977 [00:21<00:41, 31584.73 examples/s]Generating train split:  33%|███▎      | 637776/1949977 [00:21<00:40, 32801.21 examples/s]Generating train split:  33%|███▎      | 649998/1949977 [00:23<01:36, 13494.54 examples/s]Generating train split:  34%|███▍      | 659998/1949977 [00:24<01:29, 14404.23 examples/s]Generating train split:  34%|███▍      | 669998/1949977 [00:24<01:09, 18492.24 examples/s]Generating train split:  35%|███▍      | 679998/1949977 [00:24<00:59, 21282.19 examples/s]Generating train split:  35%|███▌      | 689998/1949977 [00:24<00:49, 25655.50 examples/s]Generating train split:  36%|███▌      | 699998/1949977 [00:25<00:41, 29861.18 examples/s]Generating train split:  36%|███▋      | 709998/1949977 [00:25<00:36, 34006.35 examples/s]Generating train split:  37%|███▋      | 722220/1949977 [00:26<01:04, 18946.71 examples/s]Generating train split:  38%|███▊      | 732220/1949977 [00:27<01:07, 17971.97 examples/s]Generating train split:  38%|███▊      | 742220/1949977 [00:27<00:56, 21431.69 examples/s]Generating train split:  39%|███▊      | 752220/1949977 [00:27<00:46, 25928.00 examples/s]Generating train split:  39%|███▉      | 762220/1949977 [00:27<00:41, 28819.97 examples/s]Generating train split:  40%|███▉      | 772220/1949977 [00:28<00:36, 32611.57 examples/s]Generating train split:  40%|████      | 782220/1949977 [00:28<00:33, 35151.48 examples/s]Generating train split:  41%|████▏     | 804441/1949977 [00:30<01:00, 18933.32 examples/s]Generating train split:  43%|████▎     | 844441/1949977 [00:30<00:28, 39262.63 examples/s]Generating train split:  45%|████▍     | 876662/1949977 [00:30<00:23, 46051.11 examples/s]Generating train split:  45%|████▌     | 886662/1949977 [00:31<00:34, 30691.32 examples/s]Generating train split:  48%|████▊     | 926662/1949977 [00:31<00:20, 48818.38 examples/s]Generating train split:  49%|████▊     | 948883/1949977 [00:32<00:22, 44084.08 examples/s]Generating train split:  49%|████▉     | 958883/1949977 [00:32<00:22, 43413.76 examples/s]Generating train split:  50%|████▉     | 968883/1949977 [00:33<00:34, 28271.99 examples/s]Generating train split:  52%|█████▏    | 1008883/1949977 [00:33<00:18, 51028.99 examples/s]Generating train split:  52%|█████▏    | 1021104/1949977 [00:34<00:22, 40825.79 examples/s]Generating train split:  53%|█████▎    | 1031104/1949977 [00:34<00:22, 40190.88 examples/s]Generating train split:  53%|█████▎    | 1041104/1949977 [00:35<00:23, 38920.45 examples/s]Generating train split:  54%|█████▍    | 1051104/1949977 [00:36<00:37, 23864.28 examples/s]Generating train split:  55%|█████▍    | 1071104/1949977 [00:36<00:27, 32019.05 examples/s]Generating train split:  56%|█████▌    | 1093325/1949977 [00:36<00:26, 32663.37 examples/s]Generating train split:  57%|█████▋    | 1103325/1949977 [00:37<00:25, 33692.29 examples/s]Generating train split:  57%|█████▋    | 1113325/1949977 [00:37<00:23, 36019.38 examples/s]Generating train split:  58%|█████▊    | 1123325/1949977 [00:37<00:23, 35906.38 examples/s]Generating train split:  58%|█████▊    | 1133325/1949977 [00:39<01:00, 13476.18 examples/s]Generating train split:  60%|█████▉    | 1165546/1949977 [00:40<00:33, 23293.20 examples/s]Generating train split:  60%|██████    | 1175546/1949977 [00:40<00:30, 25071.29 examples/s]Generating train split:  61%|██████    | 1185546/1949977 [00:40<00:27, 27954.03 examples/s]Generating train split:  61%|██████▏   | 1195546/1949977 [00:41<00:24, 30534.87 examples/s]Generating train split:  62%|██████▏   | 1205546/1949977 [00:41<00:22, 33112.40 examples/s]Generating train split:  62%|██████▏   | 1215546/1949977 [00:42<00:40, 17941.54 examples/s]Generating train split:  63%|██████▎   | 1237767/1949977 [00:43<00:30, 23533.60 examples/s]Generating train split:  64%|██████▍   | 1247767/1949977 [00:43<00:26, 26313.86 examples/s]Generating train split:  65%|██████▍   | 1257767/1949977 [00:43<00:24, 28576.14 examples/s]Generating train split:  65%|██████▌   | 1267767/1949977 [00:43<00:22, 30904.16 examples/s]Generating train split:  66%|██████▌   | 1277767/1949977 [00:44<00:20, 32743.42 examples/s]Generating train split:  66%|██████▌   | 1287767/1949977 [00:44<00:22, 29154.63 examples/s]Generating train split:  67%|██████▋   | 1297767/1949977 [00:45<00:33, 19676.83 examples/s]Generating train split:  67%|██████▋   | 1309988/1949977 [00:46<00:30, 20698.52 examples/s]Generating train split:  68%|██████▊   | 1319988/1949977 [00:46<00:26, 23769.54 examples/s]Generating train split:  68%|██████▊   | 1329988/1949977 [00:46<00:22, 27621.75 examples/s]Generating train split:  69%|██████▊   | 1339988/1949977 [00:46<00:21, 27900.85 examples/s]Generating train split:  69%|██████▉   | 1349988/1949977 [00:47<00:19, 30767.42 examples/s]Generating train split:  70%|██████▉   | 1359988/1949977 [00:47<00:17, 32890.56 examples/s]Generating train split:  70%|███████   | 1369988/1949977 [00:48<00:30, 19239.13 examples/s]Generating train split:  71%|███████   | 1382209/1949977 [00:48<00:28, 19981.99 examples/s]Generating train split:  71%|███████▏  | 1392209/1949977 [00:49<00:23, 23352.06 examples/s]Generating train split:  72%|███████▏  | 1402209/1949977 [00:49<00:21, 25978.52 examples/s]Generating train split:  72%|███████▏  | 1412209/1949977 [00:49<00:18, 28839.39 examples/s]Generating train split:  73%|███████▎  | 1422209/1949977 [00:49<00:16, 31460.10 examples/s]Generating train split:  73%|███████▎  | 1432209/1949977 [00:50<00:15, 33161.67 examples/s]Generating train split:  74%|███████▍  | 1442209/1949977 [00:51<00:26, 19234.12 examples/s]Generating train split:  75%|███████▍  | 1454430/1949977 [00:51<00:24, 20277.80 examples/s]Generating train split:  75%|███████▌  | 1464430/1949977 [00:52<00:20, 23960.51 examples/s]Generating train split:  76%|███████▌  | 1474430/1949977 [00:52<00:17, 27601.58 examples/s]Generating train split:  76%|███████▌  | 1484430/1949977 [00:52<00:15, 30462.44 examples/s]Generating train split:  77%|███████▋  | 1494430/1949977 [00:52<00:13, 34031.49 examples/s]Generating train split:  77%|███████▋  | 1504430/1949977 [00:52<00:12, 35942.23 examples/s]Generating train split:  78%|███████▊  | 1516651/1949977 [00:54<00:22, 19404.77 examples/s]Generating train split:  78%|███████▊  | 1526651/1949977 [00:54<00:22, 19104.56 examples/s]Generating train split:  79%|███████▉  | 1536651/1949977 [00:54<00:18, 22927.98 examples/s]Generating train split:  79%|███████▉  | 1546651/1949977 [00:55<00:15, 26263.62 examples/s]Generating train split:  80%|███████▉  | 1556651/1949977 [00:55<00:12, 31074.43 examples/s]Generating train split:  80%|████████  | 1566651/1949977 [00:55<00:11, 33746.01 examples/s]Generating train split:  81%|████████  | 1576651/1949977 [00:55<00:10, 35059.28 examples/s]Generating train split:  82%|████████▏ | 1598872/1949977 [00:57<00:17, 20556.05 examples/s]Generating train split:  84%|████████▍ | 1638872/1949977 [00:57<00:07, 42368.91 examples/s]Generating train split:  85%|████████▌ | 1658872/1949977 [00:57<00:05, 52098.25 examples/s]Generating train split:  86%|████████▌ | 1671093/1949977 [00:58<00:06, 40981.40 examples/s]Generating train split:  86%|████████▌ | 1681093/1949977 [00:59<00:12, 20723.62 examples/s]Generating train split:  88%|████████▊ | 1721093/1949977 [00:59<00:05, 39925.57 examples/s]Generating train split:  89%|████████▉ | 1743314/1949977 [01:00<00:05, 39491.85 examples/s]Generating train split:  90%|█████████ | 1763314/1949977 [01:02<00:07, 24783.32 examples/s]Generating train split:  92%|█████████▏| 1803314/1949977 [01:02<00:03, 41243.44 examples/s]Generating train split:  94%|█████████▎| 1825535/1949977 [01:02<00:03, 37762.06 examples/s]Generating train split:  95%|█████████▍| 1845535/1949977 [01:04<00:04, 26077.14 examples/s]Generating train split:  97%|█████████▋| 1887756/1949977 [01:05<00:01, 34655.14 examples/s]Generating train split:  97%|█████████▋| 1897756/1949977 [01:05<00:01, 35678.97 examples/s]Generating train split:  98%|█████████▊| 1907756/1949977 [01:05<00:01, 35582.80 examples/s]Generating train split:  98%|█████████▊| 1917756/1949977 [01:05<00:00, 35527.93 examples/s]Generating train split:  99%|█████████▉| 1927756/1949977 [01:07<00:01, 20563.75 examples/s]Generating train split: 100%|██████████| 1949977/1949977 [01:07<00:00, 28833.53 examples/s]
2025-09-18 15:43:00,282 - ERROR - Failed to load DETOX dataset. Aborting. Error: 'text'
2025-09-18 15:44:29,024 - INFO - Loading configuration from config/smoke_test.yaml
2025-09-18 15:44:29,071 - INFO - Environment set up with random seed: 42
2025-09-18 15:44:29,071 - INFO - ====== Starting Phase 1: Data Preprocessing ======
2025-09-18 15:44:29,071 - INFO - Starting preprocessing...
Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.
2025-09-18 15:44:29,247 - INFO - Loading Alpaca dataset (as PromptSource substitute)
2025-09-18 15:44:32,236 - INFO - Loading LAION-Aesthetics dataset (as Stable Diffusion logs substitute)
2025-09-18 15:44:35,182 - INFO - Loading DETOX dataset for safety labels
2025-09-18 15:44:38,192 - INFO - Total processed examples: 768
2025-09-18 15:44:38,372 - INFO - Total examples with language ID: 768
2025-09-18 15:44:38,387 - INFO - Saved datasets to data/processed/smoke_test
2025-09-18 15:44:38,387 - INFO - Train size: 614, Val size: 77, Test size: 77
2025-09-18 15:44:38,387 - INFO - Preprocessing finished successfully.
2025-09-18 15:44:38,402 - INFO - ====== Finished Phase 1: Data Preprocessing ======
2025-09-18 15:44:38,402 - INFO - 
====== Starting Phase 2: Model Training ======
2025-09-18 15:44:38,402 - INFO - Starting training process...
2025-09-18 15:44:38,403 - INFO - Loading preprocessed data.
2025-09-18 15:44:38,405 - CRITICAL - An unhandled exception occurred during the pipeline: Weights only load failed. This file can still be loaded, to do so you have two options, [1mdo those steps only if you trust the source of the checkpoint[0m. 
	(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.
	(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.
	WeightsUnpickler error: Unsupported global: GLOBAL src.preprocess.PreprocessedDataset was not an allowed global by default. Please use `torch.serialization.add_safe_globals([src.preprocess.PreprocessedDataset])` or the `torch.serialization.safe_globals([src.preprocess.PreprocessedDataset])` context manager to allowlist this global if you trust this class/function.

Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.
Traceback (most recent call last):
  File "/home/toma/pt-80-1-a-13/_work/experiment_matsuzawa_250918_5/experiment_matsuzawa_250918_5/src/main.py", line 69, in main
    train.run_training(config)
  File "/home/toma/pt-80-1-a-13/_work/experiment_matsuzawa_250918_5/experiment_matsuzawa_250918_5/src/train.py", line 145, in run_training
    train_data = torch.load(os.path.join(processed_dir, 'train_data.pt'))
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/toma/pt-80-1-a-13/_work/experiment_matsuzawa_250918_5/experiment_matsuzawa_250918_5/.venv/lib/python3.11/site-packages/torch/serialization.py", line 1529, in load
    raise pickle.UnpicklingError(_get_wo_message(str(e))) from None
_pickle.UnpicklingError: Weights only load failed. This file can still be loaded, to do so you have two options, [1mdo those steps only if you trust the source of the checkpoint[0m. 
	(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.
	(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.
	WeightsUnpickler error: Unsupported global: GLOBAL src.preprocess.PreprocessedDataset was not an allowed global by default. Please use `torch.serialization.add_safe_globals([src.preprocess.PreprocessedDataset])` or the `torch.serialization.safe_globals([src.preprocess.PreprocessedDataset])` context manager to allowlist this global if you trust this class/function.

Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.
2025-09-18 15:45:41,355 - INFO - Loading configuration from config/smoke_test.yaml
2025-09-18 15:45:41,395 - INFO - Environment set up with random seed: 42
2025-09-18 15:45:41,395 - INFO - ====== Starting Phase 1: Data Preprocessing ======
2025-09-18 15:45:41,395 - INFO - Starting preprocessing...
Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.
2025-09-18 15:45:41,579 - INFO - Loading Alpaca dataset (as PromptSource substitute)
2025-09-18 15:45:46,238 - INFO - Loading LAION-Aesthetics dataset (as Stable Diffusion logs substitute)
2025-09-18 15:45:48,990 - INFO - Loading DETOX dataset for safety labels
2025-09-18 15:45:52,471 - INFO - Total processed examples: 768
2025-09-18 15:45:52,723 - INFO - Total examples with language ID: 768
2025-09-18 15:45:52,738 - INFO - Saved datasets to data/processed/smoke_test
2025-09-18 15:45:52,738 - INFO - Train size: 614, Val size: 77, Test size: 77
2025-09-18 15:45:52,738 - INFO - Preprocessing finished successfully.
2025-09-18 15:45:52,756 - INFO - ====== Finished Phase 1: Data Preprocessing ======
2025-09-18 15:45:52,756 - INFO - 
====== Starting Phase 2: Model Training ======
2025-09-18 15:45:52,756 - INFO - Starting training process...
2025-09-18 15:45:52,757 - INFO - Loading preprocessed data.
2025-09-18 15:45:52,763 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-09-18 15:45:56,552 - INFO - Phase 1: Training Safety-Unified Head and Reward Model.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:01<00:00,  1.10s/it]Batches: 100%|██████████| 1/1 [00:01<00:00,  1.10s/it]
2025-09-18 15:45:57,761 - CRITICAL - An unhandled exception occurred during the pipeline: Inference tensors cannot be saved for backward. To work around you can make a clone to get a normal tensor and use it in autograd.
Traceback (most recent call last):
  File "/home/toma/pt-80-1-a-13/_work/experiment_matsuzawa_250918_5/experiment_matsuzawa_250918_5/src/main.py", line 69, in main
    train.run_training(config)
  File "/home/toma/pt-80-1-a-13/_work/experiment_matsuzawa_250918_5/experiment_matsuzawa_250918_5/src/train.py", line 177, in run_training
    safety_logits, latent_embeddings = safety_head(embeddings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/toma/pt-80-1-a-13/_work/experiment_matsuzawa_250918_5/experiment_matsuzawa_250918_5/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/toma/pt-80-1-a-13/_work/experiment_matsuzawa_250918_5/experiment_matsuzawa_250918_5/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/toma/pt-80-1-a-13/_work/experiment_matsuzawa_250918_5/experiment_matsuzawa_250918_5/src/train.py", line 36, in forward
    latent = torch.relu(self.projector(x))
                        ^^^^^^^^^^^^^^^^^
  File "/home/toma/pt-80-1-a-13/_work/experiment_matsuzawa_250918_5/experiment_matsuzawa_250918_5/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/toma/pt-80-1-a-13/_work/experiment_matsuzawa_250918_5/experiment_matsuzawa_250918_5/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/toma/pt-80-1-a-13/_work/experiment_matsuzawa_250918_5/experiment_matsuzawa_250918_5/.venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 125, in forward
    return F.linear(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Inference tensors cannot be saved for backward. To work around you can make a clone to get a normal tensor and use it in autograd.
